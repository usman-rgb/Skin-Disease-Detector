{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vc17k5PgAuFV",
        "outputId": "578e9f2c-6ed9-4972-e118-8f236e490cb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow numpy pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ke8GByk6A5MW",
        "outputId": "b9c9e467-a2fc-4b77-b916-679b6b4a121a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Custom Focal Loss for Sparse Labels (Fixed)\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def focal_loss_fn(y_true, y_pred):\n",
        "        # Convert sparse labels to one-hot\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=3)  # num_classes=3\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "\n",
        "        # Compute cross-entropy loss\n",
        "        ce_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "        # Compute focal weight\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)  # Probability of true class\n",
        "        focal_weight = tf.pow(1 - p_t, gamma) * alpha\n",
        "\n",
        "        # Compute final focal loss\n",
        "        return tf.reduce_mean(focal_weight * ce_loss)\n",
        "    return focal_loss_fn\n",
        "\n",
        "# Cosine Decay Learning Rate Schedule\n",
        "def cosine_decay(epoch, initial_lr=0.0001):\n",
        "    epochs_total = 20\n",
        "    cosine_decay = 0.5 * (1 + np.cos(np.pi * epoch / epochs_total))\n",
        "    return float(initial_lr * cosine_decay)\n",
        "\n",
        "# ======================\n",
        "# 1. DATA PREPARATION\n",
        "# ======================\n",
        "\n",
        "dataset = \"/content/drive/MyDrive/Skin Disease Dataset Short\"\n",
        "img_size = (300, 300)\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.05,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.95, 1.05],\n",
        "    channel_shift_range=5.0,\n",
        "    fill_mode='reflect',\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
        ")\n",
        "\n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "    dataset,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_ds = val_datagen.flow_from_directory(\n",
        "    dataset,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "class_names = list(train_ds.class_indices.keys())\n",
        "print(\"Detected classes:\", class_names)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# ======================\n",
        "# 2. DISEASE KNOWLEDGE BASE (Unchanged)\n",
        "# ======================\n",
        "\n",
        "DISEASE_DATABASE = {\n",
        "    \"Atopic Dermatitis\": {\n",
        "        \"description\": \"Chronic inflammatory skin condition often associated with allergies\",\n",
        "        \"severity\": \"Moderate\",\n",
        "        \"treatments\": [\n",
        "            \"Use fragrance-free moisturizers daily\",\n",
        "            \"Apply topical corticosteroids during flare-ups\",\n",
        "            \"Consider wet wrap therapy for severe cases\",\n",
        "            \"Identify and avoid triggers like dust or certain fabrics\"\n",
        "        ],\n",
        "        \"when_to_see_doctor\": \"If symptoms persist after 2 weeks of home care\"\n",
        "    },\n",
        "    \"Eczema\": {\n",
        "        \"description\": \"Condition causing itchy, inflamed skin patches\",\n",
        "        \"severity\": \"Mild-Moderate\",\n",
        "        \"treatments\": [\n",
        "            \"Apply hydrocortisone cream (1%) to affected areas\",\n",
        "            \"Use antihistamines for itch relief\",\n",
        "            \"Moisturize with ceramide-based creams\",\n",
        "            \"Avoid scratching to prevent infection\"\n",
        "        ],\n",
        "        \"when_to_see_doctor\": \"If rash covers large areas or shows signs of infection\"\n",
        "    },\n",
        "    \"Psoriasis pictures Lichen Planus and related diseases\": {\n",
        "        \"description\": \"Autoimmune disorder causing rapid skin cell buildup\",\n",
        "        \"severity\": \"Moderate-Severe\",\n",
        "        \"treatments\": [\n",
        "            \"Apply topical treatments containing salicylic acid\",\n",
        "            \"Use prescribed vitamin D analogs\",\n",
        "            \"Consider phototherapy treatment\",\n",
        "            \"Manage stress which can trigger flare-ups\"\n",
        "        ],\n",
        "        \"when_to_see_doctor\": \"For diagnosis and prescription treatments\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# ======================\n",
        "# 3. MODEL ARCHITECTURE\n",
        "# ======================\n",
        "\n",
        "def build_model():\n",
        "    base_model = EfficientNetB3(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(*img_size, 3)\n",
        "    )\n",
        "\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:100]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu', kernel_regularizer=l2(1e-4)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu', kernel_regularizer=l2(1e-4)),\n",
        "        BatchNormalization(),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# ======================\n",
        "# 4. TRAINING CONFIGURATION\n",
        "# ======================\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss=focal_loss(gamma=2.0, alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.LearningRateScheduler(cosine_decay),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
        "    tf.keras.callbacks.TerminateOnNaN()\n",
        "]\n",
        "\n",
        "# ======================\n",
        "# 5. MODEL TRAINING (20 EPOCHS)\n",
        "# ======================\n",
        "\n",
        "print(\"\\n=== Training ===\")\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=20,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ======================\n",
        "# 6. PREDICTION & REPORT GENERATION\n",
        "# ======================\n",
        "\n",
        "def generate_diagnostic_report(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_array = np.array(img.resize(img_size))\n",
        "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    pred = model.predict(img_array, verbose=0)\n",
        "    pred_class = class_names[np.argmax(pred)]\n",
        "    confidence = np.max(pred)\n",
        "    disease_info = DISEASE_DATABASE[pred_class]\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Input Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.text(0.1, 0.5,\n",
        "             f\"Diagnosis: {pred_class}\\n\\n\"\n",
        "             f\"Confidence: {confidence:.1%}\\n\\n\"\n",
        "             f\"Severity: {disease_info['severity']}\\n\\n\"\n",
        "             f\"Description: {disease_info['description']}\",\n",
        "             fontsize=12)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    treatment_text = \"Recommended Treatments:\\n\\n\" + \"\\n\".join(\n",
        "        f\"â€¢ {treatment}\" for treatment in disease_info['treatments']\n",
        "    )\n",
        "    plt.text(0.1, 0.1, treatment_text, fontsize=12)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"ğŸ©º CLINICAL NOTES: {disease_info['when_to_see_doctor']}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return {\n",
        "        \"diagnosis\": pred_class,\n",
        "        \"confidence\": float(confidence),\n",
        "        \"severity\": disease_info[\"severity\"],\n",
        "        \"treatments\": disease_info[\"treatments\"],\n",
        "        \"clinical_notes\": disease_info[\"when_to_see_doctor\"]\n",
        "    }\n",
        "\n",
        "# Example usage:\n",
        "# report = generate_diagnostic_report(\"path_to_image.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6C7pz0IQ21j",
        "outputId": "a95986a6-df7f-4e2e-d62a-81d0dbeb748f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3992 images belonging to 3 classes.\n",
            "Found 997 images belonging to 3 classes.\n",
            "Detected classes: ['Atopic Dermatitis', 'Eczema', 'Psoriasis pictures Lichen Planus and related diseases']\n",
            "\n",
            "=== Training ===\n",
            "Epoch 1/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 2s/step - accuracy: 0.4079 - loss: 0.2881 - val_accuracy: 0.3872 - val_loss: 0.1993 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.5315 - loss: 0.2154 - val_accuracy: 0.4233 - val_loss: 0.2446 - learning_rate: 9.9384e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.5955 - loss: 0.1865 - val_accuracy: 0.4213 - val_loss: 0.3210 - learning_rate: 9.6952e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.6314 - loss: 0.1709 - val_accuracy: 0.4383 - val_loss: 0.3780 - learning_rate: 9.1669e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.6656 - loss: 0.1549 - val_accuracy: 0.4524 - val_loss: 0.3891 - learning_rate: 4.1458e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.7004 - loss: 0.1439 - val_accuracy: 0.4483 - val_loss: 0.3982 - learning_rate: 3.5386e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.6853 - loss: 0.1457 - val_accuracy: 0.4534 - val_loss: 0.4094 - learning_rate: 2.8093e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.7041 - loss: 0.1454 - val_accuracy: 0.4594 - val_loss: 0.4037 - learning_rate: 1.0212e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.7108 - loss: 0.1373 - val_accuracy: 0.4624 - val_loss: 0.4049 - learning_rate: 6.6836e-06\n",
            "Epoch 10/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.7201 - loss: 0.1340 - val_accuracy: 0.4564 - val_loss: 0.4103 - learning_rate: 3.8646e-06\n",
            "Epoch 11/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.7199 - loss: 0.1383 - val_accuracy: 0.4574 - val_loss: 0.4086 - learning_rate: 9.6615e-07\n",
            "Epoch 12/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.6957 - loss: 0.1405 - val_accuracy: 0.4574 - val_loss: 0.4047 - learning_rate: 4.0751e-07\n",
            "Epoch 13/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.7155 - loss: 0.1356 - val_accuracy: 0.4574 - val_loss: 0.4079 - learning_rate: 1.4079e-07\n",
            "Epoch 14/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.7165 - loss: 0.1328 - val_accuracy: 0.4604 - val_loss: 0.4039 - learning_rate: 3.8436e-08\n",
            "Epoch 15/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.7182 - loss: 0.1408 - val_accuracy: 0.4544 - val_loss: 0.4085 - learning_rate: 7.9220e-09\n",
            "Epoch 16/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 1s/step - accuracy: 0.7144 - loss: 0.1339 - val_accuracy: 0.4604 - val_loss: 0.4018 - learning_rate: 1.1601e-09\n",
            "Epoch 17/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.7174 - loss: 0.1370 - val_accuracy: 0.4564 - val_loss: 0.4020 - learning_rate: 1.1078e-10\n",
            "Epoch 18/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.7266 - loss: 0.1333 - val_accuracy: 0.4544 - val_loss: 0.4021 - learning_rate: 6.0374e-12\n",
            "Epoch 19/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.7158 - loss: 0.1390 - val_accuracy: 0.4584 - val_loss: 0.4027 - learning_rate: 1.4775e-13\n",
            "Epoch 20/20\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.7217 - loss: 0.1393 - val_accuracy: 0.4604 - val_loss: 0.4079 - learning_rate: 9.0949e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/skin_disease_model.keras\")\n"
      ],
      "metadata": {
        "id": "9F9S6s4Yz-C9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SUVifuM1xw87",
        "outputId": "15f18643-cba7-437c-f12d-bac24af62d89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.0-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.3 streamlit-1.44.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Ngrok ka authentication token replace karein apne khud ke token se\n",
        "!ngrok authtoken 2urmEk8GpIZrzYrnbQ6HQ1oMTJm_447EETWLWdGf8eDgYjckY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IShoZ25zyM3C",
        "outputId": "0c467aaf-267f-40a1-b9a1-b50aa9441c0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile SkinDiseaseDetector.py\n",
        "\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the trained model with custom objects\n",
        "MODEL_PATH = \"/content/drive/MyDrive/skin_disease_model.keras\"\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def focal_loss_fn(y_true, y_pred):\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=3)\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        ce_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "        focal_weight = tf.pow(1 - p_t, gamma) * alpha\n",
        "        return tf.reduce_mean(focal_weight * ce_loss)\n",
        "    return focal_loss_fn\n",
        "\n",
        "model = tf.keras.models.load_model(MODEL_PATH, custom_objects={\"focal_loss_fn\": focal_loss()})\n",
        "\n",
        "# Define class names (Make sure it matches training classes)\n",
        "class_names = [\"Atopic Dermatitis\", \"Eczema\", \"Psoriasis Lichen Planus\"]\n",
        "\n",
        "# Disease Knowledge Base\n",
        "DISEASE_DATABASE = {\n",
        "    \"Atopic Dermatitis\": {\n",
        "        \"description\": \"Chronic inflammatory skin condition often associated with allergies\",\n",
        "        \"severity\": \"Moderate\",\n",
        "        \"treatments\": [\n",
        "            \"Use fragrance-free moisturizers daily\",\n",
        "            \"Apply topical corticosteroids during flare-ups\",\n",
        "            \"Consider wet wrap therapy for severe cases\",\n",
        "            \"Avoid triggers like dust or certain fabrics\"\n",
        "        ],\n",
        "        \"when_to_see_doctor\": \"If symptoms persist after 2 weeks of home care\"\n",
        "    },\n",
        "    \"Eczema\": {\n",
        "        \"description\": \"Condition causing itchy, inflamed skin patches\",\n",
        "        \"severity\": \"Mild-Moderate\",\n",
        "        \"treatments\": [\n",
        "            \"Apply hydrocortisone cream (1%) to affected areas\",\n",
        "            \"Use antihistamines for itch relief\",\n",
        "            \"Moisturize with ceramide-based creams\",\n",
        "            \"Avoid scratching to prevent infection\"\n",
        "        ],\n",
        "        \"when_to_see_doctor\": \"If rash covers large areas or shows signs of infection\"\n",
        "    },\n",
        "    \"Psoriasis Lichen Planus\": {\n",
        "        \"description\": \"Autoimmune disorder causing rapid skin cell buildup\",\n",
        "        \"severity\": \"Moderate-Severe\",\n",
        "        \"treatments\": [\n",
        "            \"Apply topical treatments containing salicylic acid\",\n",
        "            \"Use prescribed vitamin D analogs\",\n",
        "            \"Consider phototherapy treatment\",\n",
        "            \"Manage stress which can trigger flare-ups\"\n",
        "        ],\n",
        "        \"when_to_see_doctor\": \"For diagnosis and prescription treatments\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Streamlit UI\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"Usman - Skin Disease Detector\", layout=\"wide\")\n",
        "    st.title(\"ğŸ©º Usman - Skin Disease Detector\")\n",
        "    st.markdown(\"### Upload an image of the affected skin area to detect the disease and get treatment recommendations.\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "        # Preprocess Image\n",
        "        img_size = (300, 300)\n",
        "        img_array = np.array(image.resize(img_size))\n",
        "        img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # Predict\n",
        "        pred = model.predict(img_array)\n",
        "        pred_class = class_names[np.argmax(pred)]\n",
        "        confidence = np.max(pred)\n",
        "        disease_info = DISEASE_DATABASE.get(pred_class, None)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(f\"ğŸ’¡ Predicted Disease: {pred_class}\")\n",
        "        st.write(f\"**Confidence Level:** {confidence:.2%}\")\n",
        "\n",
        "        if disease_info:\n",
        "            st.write(f\"**Description:** {disease_info['description']}\")\n",
        "            st.write(f\"**Severity:** {disease_info['severity']}\")\n",
        "            st.markdown(\"### ğŸ©¹ Recommended Treatments:\")\n",
        "            for treatment in disease_info[\"treatments\"]:\n",
        "                st.write(f\"- {treatment}\")\n",
        "\n",
        "            st.markdown(\"### ğŸ¥ When to See a Doctor:\")\n",
        "            st.warning(disease_info[\"when_to_see_doctor\"])\n",
        "        else:\n",
        "            st.error(\"No information found for this disease.\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.success(\"âœ… This AI-powered detector is designed to assist in preliminary diagnosis. Always consult a healthcare professional for medical advice.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1Q_QwW7xYi5",
        "outputId": "4ce2ea4a-60c4-4760-e10f-7dd88d873ae8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing SkinDiseaseDetector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ROIciG7y8ra",
        "outputId": "b8f74aab-6d5a-418a-de0e-9fbc12114848"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data  SkinDiseaseDetector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJatdRVWzC1p",
        "outputId": "644915d5-8e8a-41c9-d6cb-7e29f0325e5d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.16.130.102"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run SkinDiseaseDetector.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR8FA9Z0zKv8",
        "outputId": "5aab0a46-2f40-436b-95a9-5fc0433f7ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.130.102:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kyour url is: https://tough-months-tan.loca.lt\n",
            "2025-03-26 19:05:04.918540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743015904.942688   63888 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743015904.949822   63888 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-26 19:05:09.646314: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1743015909.646509   63888 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5582 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 266 variables whereas the saved optimizer has 530 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "2025-03-26 19:05:40.750 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1743015944.715513   63926 service.cc:148] XLA service 0x78c3a8019b90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1743015944.715566   63926 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1743015945.775373   63926 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "I0000 00:00:1743015951.075046   63926 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
            "2025-03-26 19:07:31.225 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
            "2025-03-26 19:24:19.688 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
            "2025-03-26 19:25:08.386 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
            "2025-03-26 19:28:04.688 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78c4441c3560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
            "2025-03-26 19:32:41.044 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78c444312ac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
            "2025-03-26 19:33:29.765 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n"
          ]
        }
      ]
    }
  ]
}